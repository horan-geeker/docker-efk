<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<filter docker.**>
  @type parser
  key_name log
  reserve_data true
  <parse>
    @type json
    time_key time
    time_format %Y-%m-%dT%H:%M:%S%:z
    keep_time_key true
  </parse>
</filter>

<filter docker.**>
  @type geoip

  # Specify one or more geoip lookup field which has ip address (default: host)
  geoip_lookup_key  ip

  # Set adding field with placeholder (more than one settings are required.)
  <record>
    geoip.city            ${city.names.en["ip"]}
    geoip.latitude        ${location.latitude["ip"]}
    geoip.longitude       ${location.longitude["ip"]}
    geoip.country         ${country.iso_code["ip"]}
    geoip.country_name    ${country.names.en["ip"]}
    geoip.postal_code     ${postal.code["ip"]}
    geoip.region_code     ${subdivisions.0.iso_code["ip"]}
    geoip.region_name     ${subdivisions.0.names.en["ip"]}
    geoip.location        ${latitude["remote"]},${longitude["remote"]}
    
    # lat lon as properties
    # ex. {"lat" => 37.4192008972168, "lon" => -122.05740356445312 }
    #location_properties  '{"lat":${location.latitude["ip"]},"lon":${location.longitude["ip"]}}'
    # lat lon as string
    # ex. "37.4192008972168,-122.05740356445312"
    #location_string      '${location.latitude["ip"]},${location.longitude["ip"]}'
    # lat lon as array (it is useful for Kibana's bettermap.)
    # ex. [-122.05740356445312, 37.4192008972168]
    #location_array      '[${location.longitude["ip"]},${location.latitude["ip"]}]'
  </record>

  # To avoid get stacktrace error with `[null, null]` array for elasticsearch.
  skip_adding_null_record  true
</filter>

<match docker.**>
  @type copy
  <store>
    @type stdout
  </store>
  <store>
    @type                   elasticsearch
    host                    elasticsearch
    port                    9200
    user                    "#{ENV['ELK_USER']}"
    password                "#{ENV['ELK_PASSWORD']}"
    logstash_format  true
    flush_interval       1s
  </store>
 </match>
